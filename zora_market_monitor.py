#!/usr/bin/env python3
# ZORA MODULE HEADER

"""
Module Name: zora_market_monitor
Generated by ZORA SYSTEM â€“ All rights reserved.
Real-Time Market Monitoring System for ZORA CORE
Tracks competitor prices and enables automatic undercutting
"""

import asyncio
import aiohttp
import json
import datetime
import logging
import re
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import urllib.parse
from bs4 import BeautifulSoup
import time
import random

import sys
import os
sys.path.insert(0, '/home/ubuntu/repos/ZORA-CORE')

try:
    from zora_universal_infinity_pricing import MarketPrice, ProductType, universal_pricing_engine
    from mcp_extensions.firecrawl_extension import FirecrawlExtension
    from agents.github import GitHubAgent
    from agents.meta_ai import MetaAIAgent
    from agents.gpt4 import GPT4Agent
except ImportError as e:
    print(f"âš ï¸ Import warning: {e}")

class MonitoringSource(Enum):
    WEB_SCRAPING = "web_scraping"
    API_INTEGRATION = "api_integration"
    MCP_EXTENSION = "mcp_extension"
    AI_AGENT = "ai_agent"
    MANUAL_INPUT = "manual_input"

class CompetitorType(Enum):
    DIRECT_COMPETITOR = "direct_competitor"
    INDIRECT_COMPETITOR = "indirect_competitor"
    MARKETPLACE = "marketplace"
    BRAND_PARTNER = "brand_partner"
    PRICE_AGGREGATOR = "price_aggregator"

@dataclass
class CompetitorProfile:
    competitor_id: str
    name: str
    website: str
    competitor_type: CompetitorType
    product_categories: List[str]
    pricing_patterns: Dict[str, Any]
    quality_reputation: float
    market_share: float
    monitoring_endpoints: List[str]
    last_updated: datetime.datetime
    active: bool

@dataclass
class PriceAlert:
    alert_id: str
    product_id: str
    competitor: str
    old_price: float
    new_price: float
    price_change_percent: float
    alert_type: str  # "PRICE_DROP", "PRICE_INCREASE", "NEW_COMPETITOR"
    timestamp: datetime.datetime
    action_required: bool
    suggested_response: str

@dataclass
class MarketIntelligence:
    product_category: str
    average_market_price: float
    lowest_market_price: float
    highest_market_price: float
    price_volatility: float
    market_trend: str  # "RISING", "FALLING", "STABLE"
    competitor_count: int
    quality_leaders: List[str]
    price_leaders: List[str]
    market_gaps: List[str]
    last_analysis: datetime.datetime

class ZoraMarketMonitor:
    """
    Real-Time Market Monitoring System for ZORA CORE
    
    Capabilities:
    - Continuous competitor price tracking
    - Automatic price undercutting algorithms
    - Market intelligence gathering
    - Quality vs price analysis
    - Cross-platform monitoring
    - AI-powered market insights
    """
    
    def __init__(self):
        self.name = "ZORA MARKET MONITORâ„¢"
        self.version = "1.0.0-INFINITY"
        self.founder = "Mads Pallisgaard Petersen"
        self.contact = {
            "name": "Mads Pallisgaard Petersen",
            "address": "Fjordbakken 50, Dyves Bro, 4700 NÃ¦stved",
            "phone": "+45 22822450",
            "email": "mrpallis@gmail.com",
            "organization": "ZORA CORE"
        }
        
        self.monitoring_active = False
        self.scan_interval = 300  # 5 minutes
        self.price_change_threshold = 0.05  # 5% change triggers alert
        self.undercut_margin = 0.10  # 10% undercut by default
        self.max_undercut_percentage = 0.30  # Maximum 30% undercut
        
        self.competitors = {}
        self.monitored_products = {}
        self.price_history = {}
        self.market_intelligence = {}
        self.price_alerts = []
        
        self.ai_agents = {}
        self.mcp_extensions = {}
        
        self.scraping_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        self.monitoring_sources = {
            "amazon": {
                "base_url": "https://www.amazon.com",
                "search_pattern": "/s?k={query}",
                "price_selector": ".a-price-whole",
                "title_selector": "[data-component-type='s-search-result'] h2 a span",
                "rating_selector": ".a-icon-alt"
            },
            "ebay": {
                "base_url": "https://www.ebay.com",
                "search_pattern": "/sch/i.html?_nkw={query}",
                "price_selector": ".s-item__price",
                "title_selector": ".s-item__title",
                "rating_selector": ".ebay-review-stars"
            },
            "etsy": {
                "base_url": "https://www.etsy.com",
                "search_pattern": "/search?q={query}",
                "price_selector": ".currency-value",
                "title_selector": ".listing-link",
                "rating_selector": ".shop2-review-review"
            },
            "shopify": {
                "base_url": "https://www.shopify.com",
                "search_pattern": "/search?q={query}",
                "price_selector": ".price",
                "title_selector": ".product-title",
                "rating_selector": ".rating"
            }
        }
        
        self.ai_service_sources = {
            "openai": {
                "base_url": "https://openai.com/pricing",
                "api_endpoint": "https://api.openai.com/v1/models",
                "pricing_page": "https://openai.com/pricing"
            },
            "anthropic": {
                "base_url": "https://www.anthropic.com/pricing",
                "api_endpoint": "https://api.anthropic.com/v1/models",
                "pricing_page": "https://www.anthropic.com/pricing"
            },
            "google": {
                "base_url": "https://cloud.google.com/vertex-ai/pricing",
                "api_endpoint": "https://cloud.google.com/vertex-ai/docs/reference/rest",
                "pricing_page": "https://cloud.google.com/vertex-ai/pricing"
            }
        }
        
        self.logger = self._setup_logging()
        self.session = None
        
        self._initialize_ai_agents()
        self._initialize_mcp_extensions()
        self._load_competitor_profiles()
        
        self.logger.info(f"ðŸš€ {self.name} initialized for INFINITY MONITORINGâ„¢")

    def _setup_logging(self) -> logging.Logger:
        """Setup comprehensive logging system"""
        logger = logging.getLogger("ZoraMarketMonitor")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger

    def _initialize_ai_agents(self):
        """Initialize AI agents for market intelligence"""
        try:
            self.ai_agents = {
                "github": GitHubAgent(),
                "meta_ai": MetaAIAgent(),
                "gpt4": GPT4Agent()
            }
            self.logger.info("âœ… AI agents initialized for market intelligence")
        except Exception as e:
            self.logger.warning(f"âš ï¸ AI agents initialization warning: {e}")

    def _initialize_mcp_extensions(self):
        """Initialize MCP extensions for data collection"""
        try:
            self.mcp_extensions = {
                "firecrawl": FirecrawlExtension()
            }
            self.logger.info("âœ… MCP extensions initialized for data collection")
        except Exception as e:
            self.logger.warning(f"âš ï¸ MCP extensions initialization warning: {e}")

    def _load_competitor_profiles(self):
        """Load predefined competitor profiles"""
        self.competitors["amazon"] = CompetitorProfile(
            competitor_id="amazon",
            name="Amazon",
            website="https://www.amazon.com",
            competitor_type=CompetitorType.MARKETPLACE,
            product_categories=["electronics", "books", "clothing", "home", "collectibles"],
            pricing_patterns={"strategy": "competitive", "discount_frequency": "high"},
            quality_reputation=8.5,
            market_share=0.40,
            monitoring_endpoints=["https://www.amazon.com/s?k="],
            last_updated=datetime.datetime.utcnow(),
            active=True
        )
        
        self.competitors["ebay"] = CompetitorProfile(
            competitor_id="ebay",
            name="eBay",
            website="https://www.ebay.com",
            competitor_type=CompetitorType.MARKETPLACE,
            product_categories=["collectibles", "electronics", "vintage", "rare_items"],
            pricing_patterns={"strategy": "auction_based", "discount_frequency": "medium"},
            quality_reputation=7.5,
            market_share=0.15,
            monitoring_endpoints=["https://www.ebay.com/sch/i.html?_nkw="],
            last_updated=datetime.datetime.utcnow(),
            active=True
        )
        
        self.competitors["openai"] = CompetitorProfile(
            competitor_id="openai",
            name="OpenAI",
            website="https://openai.com",
            competitor_type=CompetitorType.DIRECT_COMPETITOR,
            product_categories=["ai_services", "language_models", "api_access"],
            pricing_patterns={"strategy": "premium", "discount_frequency": "low"},
            quality_reputation=9.0,
            market_share=0.35,
            monitoring_endpoints=["https://openai.com/pricing"],
            last_updated=datetime.datetime.utcnow(),
            active=True
        )
        
        self.competitors["anthropic"] = CompetitorProfile(
            competitor_id="anthropic",
            name="Anthropic",
            website="https://www.anthropic.com",
            competitor_type=CompetitorType.DIRECT_COMPETITOR,
            product_categories=["ai_services", "language_models", "safety_ai"],
            pricing_patterns={"strategy": "competitive", "discount_frequency": "medium"},
            quality_reputation=8.8,
            market_share=0.20,
            monitoring_endpoints=["https://www.anthropic.com/pricing"],
            last_updated=datetime.datetime.utcnow(),
            active=True
        )
        
        self.logger.info(f"ðŸ“Š Loaded {len(self.competitors)} competitor profiles")

    async def start_monitoring(self):
        """Start continuous market monitoring"""
        self.logger.info("ðŸ”„ Starting INFINITY MARKET MONITORINGâ„¢")
        self.monitoring_active = True
        
        self.session = aiohttp.ClientSession(
            headers=self.scraping_headers,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        
        try:
            while self.monitoring_active:
                await self.perform_market_scan()
                await self.analyze_market_intelligence()
                await self.generate_price_alerts()
                await self.execute_automatic_responses()
                
                self.logger.info(f"ðŸ’¤ Sleeping for {self.scan_interval} seconds...")
                await asyncio.sleep(self.scan_interval)
                
        except Exception as e:
            self.logger.error(f"âŒ Market monitoring error: {e}")
        finally:
            if self.session:
                await self.session.close()

    async def perform_market_scan(self):
        """Perform comprehensive market scan across all sources"""
        self.logger.info("ðŸ” Performing market scan...")
        
        scan_tasks = []
        
        for source_name, source_config in self.monitoring_sources.items():
            if source_name in self.competitors and self.competitors[source_name].active:
                task = self.scan_ecommerce_source(source_name, source_config)
                scan_tasks.append(task)
        
        for source_name, source_config in self.ai_service_sources.items():
            if source_name in self.competitors and self.competitors[source_name].active:
                task = self.scan_ai_service_source(source_name, source_config)
                scan_tasks.append(task)
        
        if scan_tasks:
            results = await asyncio.gather(*scan_tasks, return_exceptions=True)
            
            successful_scans = sum(1 for r in results if not isinstance(r, Exception))
            self.logger.info(f"ðŸ“Š Market scan completed: {successful_scans}/{len(scan_tasks)} sources successful")

    async def scan_ecommerce_source(self, source_name: str, source_config: Dict[str, str]):
        """Scan e-commerce platform for price data"""
        try:
            search_queries = ["premium collectibles", "limited edition items", "high quality products"]
            
            for query in search_queries:
                url = source_config["base_url"] + source_config["search_pattern"].format(query=urllib.parse.quote(query))
                
                if "firecrawl" in self.mcp_extensions:
                    price_data = await self.scrape_with_firecrawl(url, source_config)
                else:
                    price_data = await self.scrape_with_aiohttp(url, source_config)
                
                if price_data:
                    await self.process_price_data(source_name, query, price_data)
                
                await asyncio.sleep(random.uniform(1, 3))
                
        except Exception as e:
            self.logger.error(f"âŒ Error scanning {source_name}: {e}")

    async def scan_ai_service_source(self, source_name: str, source_config: Dict[str, str]):
        """Scan AI service platform for pricing data"""
        try:
            pricing_url = source_config["pricing_page"]
            
            if "firecrawl" in self.mcp_extensions:
                pricing_data = await self.scrape_ai_pricing_with_firecrawl(pricing_url)
            else:
                pricing_data = await self.scrape_ai_pricing_with_aiohttp(pricing_url)
            
            if pricing_data:
                await self.process_ai_pricing_data(source_name, pricing_data)
                
        except Exception as e:
            self.logger.error(f"âŒ Error scanning AI service {source_name}: {e}")

    async def scrape_with_firecrawl(self, url: str, source_config: Dict[str, str]) -> List[Dict[str, Any]]:
        """Scrape using Firecrawl MCP extension"""
        try:
            if "firecrawl" not in self.mcp_extensions:
                return []
            
            scraped_data = await self.mcp_extensions["firecrawl"].scrape_url(url)
            
            price_data = self.extract_price_data_from_html(scraped_data, source_config)
            
            return price_data
            
        except Exception as e:
            self.logger.error(f"âŒ Firecrawl scraping error for {url}: {e}")
            return []

    async def scrape_with_aiohttp(self, url: str, source_config: Dict[str, str]) -> List[Dict[str, Any]]:
        """Scrape using aiohttp (fallback method)"""
        try:
            if not self.session:
                return []
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html_content = await response.text()
                    price_data = self.extract_price_data_from_html(html_content, source_config)
                    return price_data
                else:
                    self.logger.warning(f"âš ï¸ HTTP {response.status} for {url}")
                    return []
                    
        except Exception as e:
            self.logger.error(f"âŒ aiohttp scraping error for {url}: {e}")
            return []

    def extract_price_data_from_html(self, html_content: str, source_config: Dict[str, str]) -> List[Dict[str, Any]]:
        """Extract price data from HTML content"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            price_data = []
            
            price_elements = soup.select(source_config.get("price_selector", ".price"))
            title_elements = soup.select(source_config.get("title_selector", ".title"))
            rating_elements = soup.select(source_config.get("rating_selector", ".rating"))
            
            for i, price_elem in enumerate(price_elements[:10]):  # Limit to first 10 results
                try:
                    price_text = price_elem.get_text(strip=True)
                    price_value = self.extract_price_from_text(price_text)
                    
                    if price_value > 0:
                        title = title_elements[i].get_text(strip=True) if i < len(title_elements) else "Unknown Product"
                        rating = self.extract_rating_from_element(rating_elements[i]) if i < len(rating_elements) else 0.0
                        
                        price_data.append({
                            "title": title,
                            "price": price_value,
                            "currency": "USD",  # Default assumption
                            "rating": rating,
                            "timestamp": datetime.datetime.utcnow().isoformat()
                        })
                        
                except Exception as e:
                    continue
            
            return price_data
            
        except Exception as e:
            self.logger.error(f"âŒ HTML parsing error: {e}")
            return []

    def extract_price_from_text(self, price_text: str) -> float:
        """Extract numeric price from text"""
        try:
            price_clean = re.sub(r'[^\d.,]', '', price_text)
            price_clean = price_clean.replace(',', '')
            
            if price_clean:
                return float(price_clean)
            return 0.0
            
        except:
            return 0.0

    def extract_rating_from_element(self, rating_element) -> float:
        """Extract rating from rating element"""
        try:
            rating_text = rating_element.get_text(strip=True)
            rating_match = re.search(r'(\d+\.?\d*)', rating_text)
            
            if rating_match:
                return float(rating_match.group(1))
            return 0.0
            
        except:
            return 0.0

    async def scrape_ai_pricing_with_firecrawl(self, url: str) -> Dict[str, Any]:
        """Scrape AI service pricing using Firecrawl"""
        try:
            if "firecrawl" not in self.mcp_extensions:
                return {}
            
            scraped_data = await self.mcp_extensions["firecrawl"].scrape_url(url)
            
            pricing_data = self.extract_ai_pricing_from_content(scraped_data)
            
            return pricing_data
            
        except Exception as e:
            self.logger.error(f"âŒ AI pricing scraping error for {url}: {e}")
            return {}

    async def scrape_ai_pricing_with_aiohttp(self, url: str) -> Dict[str, Any]:
        """Scrape AI service pricing using aiohttp"""
        try:
            if not self.session:
                return {}
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    html_content = await response.text()
                    pricing_data = self.extract_ai_pricing_from_content(html_content)
                    return pricing_data
                else:
                    return {}
                    
        except Exception as e:
            self.logger.error(f"âŒ AI pricing scraping error for {url}: {e}")
            return {}

    def extract_ai_pricing_from_content(self, content: str) -> Dict[str, Any]:
        """Extract AI service pricing from content"""
        try:
            pricing_patterns = [
                r'\$(\d+\.?\d*)\s*per\s*1000\s*tokens',
                r'\$(\d+\.?\d*)\s*per\s*month',
                r'\$(\d+\.?\d*)\s*per\s*request',
                r'(\d+\.?\d*)\s*cents\s*per\s*1000\s*tokens'
            ]
            
            pricing_data = {}
            
            for pattern in pricing_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    pricing_data["prices"] = [float(match) for match in matches]
                    break
            
            tier_patterns = [
                r'(free|basic|pro|premium|enterprise)',
                r'(starter|standard|advanced|ultimate)'
            ]
            
            for pattern in tier_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    pricing_data["tiers"] = list(set(matches))
                    break
            
            pricing_data["timestamp"] = datetime.datetime.utcnow().isoformat()
            
            return pricing_data
            
        except Exception as e:
            self.logger.error(f"âŒ AI pricing extraction error: {e}")
            return {}

    async def process_price_data(self, source_name: str, query: str, price_data: List[Dict[str, Any]]):
        """Process and store price data"""
        try:
            for item in price_data:
                market_price = MarketPrice(
                    competitor=source_name,
                    price=item["price"],
                    currency=item.get("currency", "USD"),
                    quality_score=item.get("rating", 7.5),
                    availability=True,
                    last_updated=datetime.datetime.utcnow(),
                    source_url=f"{source_name}_search_{query}",
                    confidence=0.8
                )
                
                key = f"{source_name}_{query}_{item['title']}"
                if key not in self.price_history:
                    self.price_history[key] = []
                
                self.price_history[key].append(market_price)
                
                if len(self.price_history[key]) > 100:
                    self.price_history[key] = self.price_history[key][-100:]
            
            self.logger.info(f"ðŸ“Š Processed {len(price_data)} price entries from {source_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ Price data processing error: {e}")

    async def process_ai_pricing_data(self, source_name: str, pricing_data: Dict[str, Any]):
        """Process AI service pricing data"""
        try:
            if "prices" in pricing_data:
                for price in pricing_data["prices"]:
                    market_price = MarketPrice(
                        competitor=source_name,
                        price=price,
                        currency="USD",
                        quality_score=self.competitors[source_name].quality_reputation,
                        availability=True,
                        last_updated=datetime.datetime.utcnow(),
                        source_url=f"{source_name}_pricing_page",
                        confidence=0.9
                    )
                    
                    key = f"{source_name}_ai_service"
                    if key not in self.price_history:
                        self.price_history[key] = []
                    
                    self.price_history[key].append(market_price)
            
            self.logger.info(f"ðŸ¤– Processed AI pricing data from {source_name}")
            
        except Exception as e:
            self.logger.error(f"âŒ AI pricing data processing error: {e}")

    async def analyze_market_intelligence(self):
        """Analyze market data to generate intelligence"""
        try:
            self.logger.info("ðŸ§  Analyzing market intelligence...")
            
            categories = set()
            for key in self.price_history.keys():
                category = key.split('_')[1] if '_' in key else "general"
                categories.add(category)
            
            for category in categories:
                intelligence = await self.generate_market_intelligence(category)
                self.market_intelligence[category] = intelligence
            
            self.logger.info(f"ðŸ“ˆ Generated intelligence for {len(categories)} categories")
            
        except Exception as e:
            self.logger.error(f"âŒ Market intelligence analysis error: {e}")

    async def generate_market_intelligence(self, category: str) -> MarketIntelligence:
        """Generate market intelligence for a category"""
        try:
            category_prices = []
            competitors = set()
            
            for key, price_list in self.price_history.items():
                if category in key:
                    for price_entry in price_list[-10:]:  # Last 10 entries
                        category_prices.append(price_entry.price)
                        competitors.add(price_entry.competitor)
            
            if not category_prices:
                return MarketIntelligence(
                    product_category=category,
                    average_market_price=0.0,
                    lowest_market_price=0.0,
                    highest_market_price=0.0,
                    price_volatility=0.0,
                    market_trend="UNKNOWN",
                    competitor_count=0,
                    quality_leaders=[],
                    price_leaders=[],
                    market_gaps=[],
                    last_analysis=datetime.datetime.utcnow()
                )
            
            avg_price = sum(category_prices) / len(category_prices)
            min_price = min(category_prices)
            max_price = max(category_prices)
            
            variance = sum((p - avg_price) ** 2 for p in category_prices) / len(category_prices)
            volatility = variance ** 0.5
            
            recent_prices = category_prices[-5:] if len(category_prices) >= 5 else category_prices
            older_prices = category_prices[:-5] if len(category_prices) >= 10 else category_prices[:len(category_prices)//2]
            
            if recent_prices and older_prices:
                recent_avg = sum(recent_prices) / len(recent_prices)
                older_avg = sum(older_prices) / len(older_prices)
                
                if recent_avg > older_avg * 1.05:
                    trend = "RISING"
                elif recent_avg < older_avg * 0.95:
                    trend = "FALLING"
                else:
                    trend = "STABLE"
            else:
                trend = "STABLE"
            
            return MarketIntelligence(
                product_category=category,
                average_market_price=avg_price,
                lowest_market_price=min_price,
                highest_market_price=max_price,
                price_volatility=volatility,
                market_trend=trend,
                competitor_count=len(competitors),
                quality_leaders=list(competitors)[:3],  # Top 3 by default
                price_leaders=list(competitors)[:3],   # Top 3 by default
                market_gaps=["premium_quality", "budget_friendly"],  # Placeholder
                last_analysis=datetime.datetime.utcnow()
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Market intelligence generation error: {e}")
            return MarketIntelligence(
                product_category=category,
                average_market_price=0.0,
                lowest_market_price=0.0,
                highest_market_price=0.0,
                price_volatility=0.0,
                market_trend="ERROR",
                competitor_count=0,
                quality_leaders=[],
                price_leaders=[],
                market_gaps=[],
                last_analysis=datetime.datetime.utcnow()
            )

    async def generate_price_alerts(self):
        """Generate price alerts based on market changes"""
        try:
            new_alerts = []
            
            for key, price_list in self.price_history.items():
                if len(price_list) >= 2:
                    current_price = price_list[-1]
                    previous_price = price_list[-2]
                    
                    price_change = (current_price.price - previous_price.price) / previous_price.price
                    
                    if abs(price_change) >= self.price_change_threshold:
                        alert_type = "PRICE_DROP" if price_change < 0 else "PRICE_INCREASE"
                        
                        alert = PriceAlert(
                            alert_id=f"alert_{int(time.time())}_{hash(key) % 10000}",
                            product_id=key,
                            competitor=current_price.competitor,
                            old_price=previous_price.price,
                            new_price=current_price.price,
                            price_change_percent=price_change * 100,
                            alert_type=alert_type,
                            timestamp=datetime.datetime.utcnow(),
                            action_required=alert_type == "PRICE_DROP",
                            suggested_response=self.generate_suggested_response(alert_type, price_change)
                        )
                        
                        new_alerts.append(alert)
            
            self.price_alerts.extend(new_alerts)
            
            if len(self.price_alerts) > 1000:
                self.price_alerts = self.price_alerts[-1000:]
            
            if new_alerts:
                self.logger.info(f"ðŸš¨ Generated {len(new_alerts)} price alerts")
            
        except Exception as e:
            self.logger.error(f"âŒ Price alert generation error: {e}")

    def generate_suggested_response(self, alert_type: str, price_change: float) -> str:
        """Generate suggested response for price alert"""
        if alert_type == "PRICE_DROP":
            if abs(price_change) > 0.20:  # More than 20% drop
                return "AGGRESSIVE_UNDERCUT: Match competitor price and undercut by 15%"
            else:
                return "MODERATE_UNDERCUT: Match competitor price and undercut by 10%"
        elif alert_type == "PRICE_INCREASE":
            if price_change > 0.15:  # More than 15% increase
                return "OPPORTUNITY: Maintain current price for competitive advantage"
            else:
                return "MONITOR: Watch for further price movements"
        
        return "NO_ACTION: Continue monitoring"

    async def execute_automatic_responses(self):
        """Execute automatic responses to price alerts"""
        try:
            actions_taken = 0
            
            for alert in self.price_alerts[-10:]:  # Process last 10 alerts
                if alert.action_required and "UNDERCUT" in alert.suggested_response:
                    undercut_percentage = 0.15 if "AGGRESSIVE" in alert.suggested_response else 0.10
                    new_zora_price = alert.new_price * (1 - undercut_percentage)
                    
                    await self.apply_automatic_price_update(alert.product_id, new_zora_price, alert)
                    actions_taken += 1
            
            if actions_taken > 0:
                self.logger.info(f"âš¡ Executed {actions_taken} automatic price responses")
            
        except Exception as e:
            self.logger.error(f"âŒ Automatic response execution error: {e}")

    async def apply_automatic_price_update(self, product_id: str, new_price: float, alert: PriceAlert):
        """Apply automatic price update"""
        try:
            self.logger.info(f"ðŸ’° Auto-updating price for {product_id}: ${new_price:.2f} (response to {alert.competitor})")
            
            update_record = {
                "product_id": product_id,
                "old_price": "current_zora_price",  # Would get from pricing engine
                "new_price": new_price,
                "reason": f"Automatic response to {alert.competitor} {alert.alert_type}",
                "timestamp": datetime.datetime.utcnow().isoformat(),
                "alert_id": alert.alert_id
            }
            
            if not hasattr(self, 'price_updates'):
                self.price_updates = []
            
            self.price_updates.append(update_record)
            
        except Exception as e:
            self.logger.error(f"âŒ Price update application error: {e}")

    def get_monitoring_status(self) -> Dict[str, Any]:
        """Get comprehensive monitoring status"""
        return {
            "monitor_name": self.name,
            "version": self.version,
            "monitoring_active": self.monitoring_active,
            "scan_interval": self.scan_interval,
            "competitors_tracked": len(self.competitors),
            "active_competitors": sum(1 for c in self.competitors.values() if c.active),
            "products_monitored": len(self.monitored_products),
            "price_history_entries": sum(len(prices) for prices in self.price_history.values()),
            "market_intelligence_categories": len(self.market_intelligence),
            "active_alerts": len([a for a in self.price_alerts if a.action_required]),
            "total_alerts": len(self.price_alerts),
            "ai_agents_available": len(self.ai_agents),
            "mcp_extensions_available": len(self.mcp_extensions),
            "contact_info": self.contact,
            "last_updated": datetime.datetime.utcnow().isoformat()
        }

    def export_market_data(self) -> str:
        """Export market data as JSON"""
        export_data = {
            "competitors": {k: asdict(v) for k, v in self.competitors.items()},
            "market_intelligence": {k: asdict(v) for k, v in self.market_intelligence.items()},
            "price_alerts": [asdict(alert) for alert in self.price_alerts[-100:]],  # Last 100 alerts
            "monitoring_status": self.get_monitoring_status()
        }
        
        def convert_datetime(obj):
            if isinstance(obj, datetime.datetime):
                return obj.isoformat()
            elif isinstance(obj, dict):
                return {k: convert_datetime(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_datetime(item) for item in obj]
            return obj
        
        export_data = convert_datetime(export_data)
        
        return json.dumps(export_data, indent=2)

    async def stop_monitoring(self):
        """Stop market monitoring"""
        self.logger.info("ðŸ›‘ Stopping market monitoring...")
        self.monitoring_active = False
        
        if self.session:
            await self.session.close()
            self.session = None

market_monitor = ZoraMarketMonitor()

async def main():
    """
    Main function for testing the Market Monitor
    """
    print("ðŸš€ ZORA MARKET MONITORâ„¢ - TEST MODE")
    print("=" * 50)
    
    status = market_monitor.get_monitoring_status()
    print(f"\nðŸ“Š Monitor Status:")
    print(f"   Competitors Tracked: {status['competitors_tracked']}")
    print(f"   Active Competitors: {status['active_competitors']}")
    print(f"   AI Agents Available: {status['ai_agents_available']}")
    print(f"   MCP Extensions Available: {status['mcp_extensions_available']}")
    
    print(f"\nðŸ§  Testing Market Intelligence Generation...")
    intelligence = await market_monitor.generate_market_intelligence("collectibles")
    print(f"   Category: {intelligence.product_category}")
    print(f"   Market Trend: {intelligence.market_trend}")
    print(f"   Competitor Count: {intelligence.competitor_count}")
    
    print(f"\nðŸš¨ Testing Price Alert System...")
    await market_monitor.generate_price_alerts()
    print(f"   Total Alerts: {len(market_monitor.price_alerts)}")
    
    print(f"\nâœ… ZORA MARKET MONITORâ„¢ - READY FOR DEPLOYMENT")

if __name__ == "__main__":
    asyncio.run(main())
