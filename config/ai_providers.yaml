# ZORA CORE AI Providers Configuration
# This file defines the external AI providers and models available to ZORA CORE agents.

version: "1.0"

# Default provider settings
defaults:
  timeout: 30
  max_retries: 3
  temperature: 0.7

# AI Providers
providers:
  # OpenAI
  openai:
    name: "OpenAI"
    enabled: true
    api_base: "https://api.openai.com/v1"
    api_key_env: "OPENAI_API_KEY"
    models:
      gpt-4-turbo:
        name: "GPT-4 Turbo"
        context_window: 128000
        max_output: 4096
        cost_per_1k_input: 0.01
        cost_per_1k_output: 0.03
        capabilities:
          - text_generation
          - code_generation
          - reasoning
          - analysis
        recommended_for:
          - planning
          - code_review
          - complex_reasoning
      gpt-4o:
        name: "GPT-4o"
        context_window: 128000
        max_output: 4096
        cost_per_1k_input: 0.005
        cost_per_1k_output: 0.015
        capabilities:
          - text_generation
          - code_generation
          - vision
          - reasoning
        recommended_for:
          - general_tasks
          - multimodal
      gpt-3.5-turbo:
        name: "GPT-3.5 Turbo"
        context_window: 16385
        max_output: 4096
        cost_per_1k_input: 0.0005
        cost_per_1k_output: 0.0015
        capabilities:
          - text_generation
          - code_generation
        recommended_for:
          - simple_tasks
          - high_volume

  # Anthropic
  anthropic:
    name: "Anthropic"
    enabled: true
    api_base: "https://api.anthropic.com/v1"
    api_key_env: "ANTHROPIC_API_KEY"
    models:
      claude-3-opus:
        name: "Claude 3 Opus"
        context_window: 200000
        max_output: 4096
        cost_per_1k_input: 0.015
        cost_per_1k_output: 0.075
        capabilities:
          - text_generation
          - code_generation
          - reasoning
          - analysis
          - vision
        recommended_for:
          - complex_reasoning
          - code_generation
          - safety_analysis
      claude-3-sonnet:
        name: "Claude 3 Sonnet"
        context_window: 200000
        max_output: 4096
        cost_per_1k_input: 0.003
        cost_per_1k_output: 0.015
        capabilities:
          - text_generation
          - code_generation
          - reasoning
          - vision
        recommended_for:
          - balanced_tasks
          - code_review
      claude-3-haiku:
        name: "Claude 3 Haiku"
        context_window: 200000
        max_output: 4096
        cost_per_1k_input: 0.00025
        cost_per_1k_output: 0.00125
        capabilities:
          - text_generation
          - code_generation
        recommended_for:
          - fast_tasks
          - high_volume

  # Google
  google:
    name: "Google AI"
    enabled: true
    api_base: "https://generativelanguage.googleapis.com/v1"
    api_key_env: "GOOGLE_API_KEY"
    models:
      gemini-pro:
        name: "Gemini Pro"
        context_window: 32000
        max_output: 8192
        cost_per_1k_input: 0.00025
        cost_per_1k_output: 0.0005
        capabilities:
          - text_generation
          - code_generation
          - reasoning
        recommended_for:
          - general_tasks
          - cost_effective
      gemini-pro-vision:
        name: "Gemini Pro Vision"
        context_window: 32000
        max_output: 4096
        cost_per_1k_input: 0.00025
        cost_per_1k_output: 0.0005
        capabilities:
          - text_generation
          - vision
        recommended_for:
          - multimodal
          - image_analysis

  # Perplexity (for research)
  perplexity:
    name: "Perplexity AI"
    enabled: true
    api_base: "https://api.perplexity.ai"
    api_key_env: "PERPLEXITY_API_KEY"
    models:
      sonar-medium-online:
        name: "Sonar Medium Online"
        context_window: 12000
        max_output: 4096
        cost_per_1k_input: 0.001
        cost_per_1k_output: 0.001
        capabilities:
          - text_generation
          - web_search
          - research
        recommended_for:
          - research
          - fact_checking
          - current_events

  # DeepSeek (for code)
  deepseek:
    name: "DeepSeek"
    enabled: true
    api_base: "https://api.deepseek.com/v1"
    api_key_env: "DEEPSEEK_API_KEY"
    models:
      deepseek-coder:
        name: "DeepSeek Coder"
        context_window: 16000
        max_output: 4096
        cost_per_1k_input: 0.0001
        cost_per_1k_output: 0.0002
        capabilities:
          - code_generation
          - code_completion
          - debugging
        recommended_for:
          - code_generation
          - debugging
          - code_completion

# Embedding providers
embeddings:
  openai:
    name: "OpenAI Embeddings"
    enabled: true
    api_key_env: "OPENAI_API_KEY"
    models:
      text-embedding-3-large:
        name: "Text Embedding 3 Large"
        dimensions: 3072
        cost_per_1k_tokens: 0.00013
        recommended_for:
          - semantic_search
          - memory_retrieval
      text-embedding-3-small:
        name: "Text Embedding 3 Small"
        dimensions: 1536
        cost_per_1k_tokens: 0.00002
        recommended_for:
          - fast_embedding
          - high_volume

# Task type to model routing
routing:
  # Default model for each task type
  defaults:
    code_generation: "anthropic/claude-3-opus"
    code_review: "openai/gpt-4-turbo"
    planning: "openai/gpt-4-turbo"
    research: "perplexity/sonar-medium-online"
    reasoning: "anthropic/claude-3-opus"
    safety_analysis: "anthropic/claude-3-opus"
    summarization: "openai/gpt-4-turbo"
    embedding: "openai/text-embedding-3-large"
    fast_tasks: "anthropic/claude-3-haiku"
    
  # Agent-specific preferences (override defaults)
  agents:
    CONNOR:
      code_generation: "anthropic/claude-3-opus"
      debugging: "deepseek/deepseek-coder"
    LUMINA:
      planning: "openai/gpt-4-turbo"
      coordination: "anthropic/claude-3-sonnet"
    EIVOR:
      embedding: "openai/text-embedding-3-large"
      summarization: "openai/gpt-4-turbo"
    ORACLE:
      research: "perplexity/sonar-medium-online"
      reasoning: "anthropic/claude-3-opus"
    AEGIS:
      safety_analysis: "anthropic/claude-3-opus"
      policy_check: "openai/gpt-4-turbo"
    SAM:
      ui_generation: "anthropic/claude-3-opus"
      accessibility: "openai/gpt-4-turbo"

# Rate limiting
rate_limits:
  global:
    requests_per_minute: 100
    tokens_per_minute: 100000
  per_provider:
    openai:
      requests_per_minute: 60
      tokens_per_minute: 90000
    anthropic:
      requests_per_minute: 50
      tokens_per_minute: 100000
    google:
      requests_per_minute: 60
      tokens_per_minute: 32000
    perplexity:
      requests_per_minute: 20
      tokens_per_minute: 20000
    deepseek:
      requests_per_minute: 60
      tokens_per_minute: 50000

# Fallback configuration
fallbacks:
  enabled: true
  # If primary model fails, try these in order
  chains:
    code_generation:
      - "anthropic/claude-3-opus"
      - "openai/gpt-4-turbo"
      - "deepseek/deepseek-coder"
    reasoning:
      - "anthropic/claude-3-opus"
      - "openai/gpt-4-turbo"
      - "google/gemini-pro"
    fast_tasks:
      - "anthropic/claude-3-haiku"
      - "openai/gpt-3.5-turbo"
      - "google/gemini-pro"
